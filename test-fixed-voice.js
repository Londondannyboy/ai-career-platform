const puppeteer = require('puppeteer');

async function testFixedVoice() {
  console.log('üéØ Testing FIXED Hume AI Voice Functionality...\n');
  
  const browser = await puppeteer.launch({
    headless: false,
    defaultViewport: { width: 1280, height: 800 },
    args: [
      '--no-sandbox', 
      '--disable-setuid-sandbox',
      '--use-fake-ui-for-media-stream',  // Allow microphone access
      '--use-fake-device-for-media-stream',
      '--disable-web-security',
      '--allow-running-insecure-content'
    ]
  });
  
  const page = await browser.newPage();
  
  // Grant microphone permissions
  const context = browser.defaultBrowserContext();
  await context.overridePermissions('https://ai-career-platform.vercel.app', ['microphone']);
  
  try {
    console.log('1Ô∏è‚É£ Testing New Quest Voice Implementation...');
    
    // Go to the Quest page
    await page.goto('https://ai-career-platform.vercel.app/quest', { 
      waitUntil: 'networkidle2',
      timeout: 30000 
    });
    
    await new Promise(resolve => setTimeout(resolve, 3000));
    console.log('   ‚úÖ Quest page loaded');
    
    // Take screenshot of initial state
    await page.screenshot({ 
      path: `/Users/dankeegan/ai-career-platform/tests/screenshots/quest-fixed-initial-${Date.now()}.png`,
      fullPage: true 
    });
    
    console.log('\n2Ô∏è‚É£ Checking for Real Hume AI Integration...');
    
    // Listen for console messages to see the new implementation
    const consoleMessages = [];
    page.on('console', msg => {
      consoleMessages.push(`${msg.type()}: ${msg.text()}`);
      console.log(`   Console: ${msg.type()}: ${msg.text()}`);
    });
    
    // Look for the Start Quest button
    console.log('\n3Ô∏è‚É£ Testing Start Quest Button with Real Implementation...');
    
    const startButton = await page.$('button:has-text("Start Quest")');
    if (!startButton) {
      console.log('   ‚ö†Ô∏è Looking for any Start button...');
      const anyButton = await page.$('button');
      if (anyButton) {
        const buttonText = await anyButton.evaluate(el => el.textContent);
        console.log(`   Found button: "${buttonText}"`);
        
        if (buttonText.includes('Start') || buttonText.includes('Quest')) {
          console.log('   üéØ Clicking Start Quest button...');
          await anyButton.click();
          
          // Wait for voice connection
          await new Promise(resolve => setTimeout(resolve, 5000));
          
          console.log('\n4Ô∏è‚É£ Checking Voice Connection Results...');
          
          // Check for new console messages indicating real Hume AI connection
          const connectionMessages = consoleMessages.filter(msg => 
            msg.includes('Hume AI') || 
            msg.includes('microphone') || 
            msg.includes('WebSocket') ||
            msg.includes('Connected')
          );
          
          if (connectionMessages.length > 0) {
            console.log('   ‚úÖ Voice connection messages found:');
            connectionMessages.forEach(msg => console.log(`     - ${msg}`));
          } else {
            console.log('   ‚ùå No voice connection messages found');
          }
          
          // Take screenshot after clicking
          await page.screenshot({ 
            path: `/Users/dankeegan/ai-career-platform/tests/screenshots/quest-fixed-connected-${Date.now()}.png`,
            fullPage: true 
          });
          
        }
      }
    }
    
    console.log('\n5Ô∏è‚É£ Testing Microphone Access with New Implementation...');
    
    // Test microphone access
    const microphoneTest = await page.evaluate(async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const tracks = stream.getTracks();
        console.log('Microphone tracks:', tracks.length);
        tracks.forEach(track => track.stop());
        return { 
          success: true, 
          message: `Microphone access granted, ${tracks.length} tracks`,
          trackInfo: tracks.map(t => ({ kind: t.kind, label: t.label, enabled: t.enabled }))
        };
      } catch (error) {
        return { success: false, message: error.message };
      }
    });
    
    console.log(`   Microphone test: ${microphoneTest.success ? '‚úÖ' : '‚ùå'}`);
    console.log(`   Details: ${microphoneTest.message}`);
    if (microphoneTest.trackInfo) {
      console.log(`   Track info:`, microphoneTest.trackInfo);
    }
    
    console.log('\n6Ô∏è‚É£ Testing WebSocket Connection...');
    
    // Check if WebSocket connections are being made
    const wsTest = await page.evaluate(() => {
      // Check for WebSocket connections in the console or global scope
      const hasWebSocket = typeof WebSocket !== 'undefined';
      const wsConnections = window.WebSocket ? 'WebSocket available' : 'No WebSocket';
      return { hasWebSocket, wsConnections };
    });
    
    console.log(`   WebSocket available: ${wsTest.hasWebSocket ? '‚úÖ' : '‚ùå'}`);
    console.log(`   Connection status: ${wsTest.wsConnections}`);
    
    // Take final screenshot
    await page.screenshot({ 
      path: `/Users/dankeegan/ai-career-platform/tests/screenshots/quest-fixed-final-${Date.now()}.png`,
      fullPage: true 
    });
    
    console.log('\nüéØ FIXED VOICE FUNCTIONALITY TEST SUMMARY');
    console.log('==========================================');
    
    if (microphoneTest.success) {
      console.log('‚úÖ Microphone permissions working');
    } else {
      console.log('‚ùå Microphone permissions failed');
    }
    
    if (connectionMessages.length > 0) {
      console.log('‚úÖ Voice connection messages detected');
    } else {
      console.log('‚ùå No voice connection detected');
    }
    
    const successfulConsoleMessages = consoleMessages.filter(msg => 
      msg.includes('‚úÖ') || msg.includes('Connected') || msg.includes('Hume AI')
    );
    
    if (successfulConsoleMessages.length > 0) {
      console.log('‚úÖ Successful implementation indicators found');
    } else {
      console.log('‚ùå No success indicators in console');
    }
    
    console.log('\nüì∏ Screenshots saved with timestamp for analysis');
    console.log('üîç Check console output above for detailed voice integration results');
    
    // Wait a bit more to see any delayed messages
    await new Promise(resolve => setTimeout(resolve, 3000));
    
  } catch (error) {
    console.error(`‚ùå Test failed: ${error.message}`);
    await page.screenshot({ 
      path: `/Users/dankeegan/ai-career-platform/tests/screenshots/quest-fixed-error-${Date.now()}.png`,
      fullPage: true 
    });
  } finally {
    await browser.close();
  }
}

testFixedVoice().catch(console.error);